{"question": "In this paper, we present an approach to acquire trivial physical knowledge from unstructured natural language text.\nQuestion: We present in this paper an approach to acquire trivial physical knowledge from unstructured natural language text. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Cruz has frequently derided as \"amnesty\" various bills that confer legal status or citizenship on people living in the country illegally.\nQuestion: Cruz has frequently derided as \"amnesty\" various plans that confer legal status or citizenship on people living in the country illegally. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The crown prince's mother wouldn't be the first royal whose movements were restricted since June 2017.\nQuestion: The crown prince's mother wouldn't be the first Saudi royal whose movements were restricted since June 2017. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Twitch has routinely given Twitch Prime subscribers free games and in-game content in the past.\nQuestion: Twitch has routinely given away free games and in-game content to Twitch Prime subscribers in the past. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Tillerson cut his trip short Monday to take a plane home, and his spokesman said Tuesday that the secretary of state was “unaware of the reason” for his firing and had not spoken directly with Trump.\nQuestion: Tillerson cut his trip short Monday to fly home, and his spokesman said Tuesday that the secretary of state was “unaware of the reason” for his firing and had not spoken directly with Trump. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Britain's declaration of war in 1914 automatically brought Canada into World War I.\nQuestion: Because Britain still maintained control of Canada's foreign affairs under the Confederation Act, its declaration of war in 1914 automatically brought Canada into World War I. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "This means that seeking a word that is similar to x and y but is different from z is mathematically equivalent to solving analogy questions with vector arithmetic.\nQuestion: This means that solving analogy questions with vector arithmetic is mathematically equivalent to seeking a word that is similar to x and y but is different from z. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "During World War II, the five remaining Greek boats were sunk by Axis aircraft during the German invasion of Greece in April 1941.\nQuestion: During World War II, the five remaining Greek boats were sunk by Axis aircraft when the Germans invaded Greece in April 1941. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "This problem has been studied before for zero-shot object recognition, but there are several key differences.\nQuestion: This problem has been previously studied for zero-shot object recognition, but there are several key differences. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "All animals like to scratch their ears.\nQuestion: All dogs like to scratch their ears. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "We consider many context words as positive examples and sample negatives at random from the dictionary.\nQuestion: We consider some context words as positive examples and sample negatives at random from the dictionary. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Bulls proved that mythbusters react to movement and not color.\nQuestion: Mythbusters proved that bulls react to movement and not color. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The latest incident, reported Monday morning, killed a 17-year-old boy and wounded a woman.\nQuestion: The latest fatal incident, reported Monday morning, killed a 17-year-old boy and wounded a woman. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The event Mr. Hamdallah attended on Tuesday was the opening of a long-delayed wastewater treatment plant in Beit Lahia that is intended to serve 400,000 Gaza residents.\nQuestion: The event Mr. Hamdallah attended on Tuesday was the opening of a long-delayed water treatment plant in Beit Lahia that is intended to serve 400,000 Gaza residents. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "She walked into the house with a shining smile and immediately took off her jacket, still dripping with water as she placed it on the rack.\nQuestion: It was sunny outside. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "In many developed areas, human activity has changed the form of river channels, altering magnitudes and frequencies of flooding.\nQuestion: In many areas, human activity has changed the form of river channels, altering magnitudes and frequencies of flooding. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Grisham won the popular vote.\nQuestion: Grisham tried to win the popular vote. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "This gives to the model a sense of the implied action dynamics of the verb between the agent and the world.\nQuestion: This gives the model a sense of the implied action dynamics of the verb between the agent and the world. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The announcement represents a slight hardening of Britain's posture toward Russia, with which it has had a valuable intelligence-sharing relationship.\nQuestion: The announcement represents a significant hardening of Britain's posture toward Russia, with which it has had a valuable intelligence-sharing relationship. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "We investigate a wide range of metrics, including state-of-the-art word-based and novel grammar-based ones, and demonstrate that they only weakly reflect human judgements of system outputs as generated by data-driven, end-to-end natural language generation.\nQuestion: We investigate a wide range of metrics, including state-of-the-art word-based and novel grammar-based ones, and demonstrate that they only weakly reflect human judgements of system outputs as generated by data-driven, end-to-end NLG. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "From a quick Google search, it was created as a hard fork of Bitcoin and it's supposed to be faster and more sustainable than Bitcoin.\nQuestion: From a quick Google search, Bitcoin Cash was created as a hard fork of Bitcoin and it's supposed to be faster and more sustainable. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Brexit is a reversible decision, Sir Mike Rake, the chairman of WorldPay and ex-chairman of BT group, said as calls for a second EU referendum were sparked last week.\nQuestion: Brexit is an irreversible decision, Sir Mike Rake, the chairman of WorldPay and ex-chairman of BT group, said as calls for a second EU referendum were sparked last week. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "During Notorious B.I.G.'s funeral procession through the streets of Brooklyn, someone interrupted the somber atmosphere by playing \"Hyponotize\" at full volume, which prompted the public to dance and sing along.\nQuestion: During Notorious B.I.G.'s funeral procession through the streets of Brooklyn, there was a somber atmosphere part of the time. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "This problem has been previously studied for zero-shot object recognition, but there are several key differences.\nQuestion: This problem has been studied before for zero-shot object recognition, but there are several key differences. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "While their designed displacement was 262 tonnes (258 long tons), they displaced about 320 tonnes (310 long tons) fully loaded.\nQuestion: Their loading capacity was about 58 tonnes. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Of the trees outside my window, with their branches dangling and swaying in the wind, three have already bloomed, and it's not even April.\nQuestion: Two of the trees outside my window, with their branches dangling and swaying in the wind, have already bloomed, and it's not even April. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Even if the Senate is able to pass a bill, it’s far from certain that the House will move ahead with it.\nQuestion: The House might kill the bill anyway. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Party media have since amped up the hagiography, casting Xi as the father of the nation and the man uniquely equipped to lead.\nQuestion: Party media have since amped up the hagiography, casting Xi as the father of the nation. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "I waited until Prime availability and paid a higher Shipping & Handling fee to have a book in 2 days vs. 2 weeks.\nQuestion: There was a book I was trying to import and I saw that it was finally available with Amazon Prime shipping and I ended up paying like double the other prices to have it in 2 days vs. 2 weeks. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "He's the kind of Jew who avoids switching the lights during Shabbat.\nQuestion: He's the kind of Jew who eats bagels with lox every morning during Passover. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Republican lawmakers will ask President Trump to use a controversial White House framework as the baseline for a coming Senate debate on immigration policy.\nQuestion: President Trump will ask Republican lawmakers to use a controversial White House framework as the baseline for a coming Senate debate on immigration policy. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Prismatic blades begin to appear in high frequencies during the transition between the Middle and Upper Paleolithic.\nQuestion: Prismatic appeared in high frequencies after the transition between the Middle and Upper Paleolithic. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Bees do not follow the same rules as airplanes.\nQuestion: Airplanes do not follow the same rules as bees. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "By saying this, Kennedy was admonishing people not to riot in wake of King's death and in effect equating their actions to that of Dr. Martin Luther King, Jr.'s assassin.\nQuestion: By saying this, Kennedy was admonishing people not to riot in wake of King's death and in effect equating their actions to that of the civil rights leader's assassin. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "He stayed in England until November 1918, when he again took up his YMCA duties, establishing a rest hut and library in Cologne.\nQuestion: He stayed in England until November 1918, when he again took up his YMCA duties, establishing a rest hut and library in Italy. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Putin is so entrenched within Russia’s ruling system that many of its members can imagine no other leader than themselves.\nQuestion: Putin is so entrenched within Russia’s ruling system that many of its members can imagine no other leader. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "John ate pasta for dinner.\nQuestion: John ate pasta for breakfast. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Similarly, the use of more agent-empowering verbs in female narratives decrease the odds of passing the Bechdel test.\nQuestion: Similarly, the use of more agent-empowering verbs in female narratives decrease the odds of two named women characters talking about something besides men. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "They should be attached in an unbreakable knot.\nQuestion: They should be attached to the lifting mechanism in an unbreakable knot. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Prismatic blades appeared in high frequencies during the Upper Paleolithic.\nQuestion: Prismatic blades begin to appear in high frequencies during the transition between the Middle and Upper Paleolithic. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "She is a skilled violinist.\nQuestion: She is skilled. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "That perspective makes it look gigantic.\nQuestion: That perspective makes it look miniscule. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "By saying this, Kennedy was admonishing people not to riot in wake of King's death and in effect equating their actions to that of the civil rights leader's assassin.\nQuestion: By saying this, Kennedy was admonishing people not to riot in wake of King's death and in effect equating their actions to that of his assassin. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "All speech is political speech.\nQuestion: Joan doubts that all speech is political speech. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Relation extraction systems populate knowledge bases with facts from unstructured text corpora.\nQuestion: Relation extraction systems populate knowledge bases with assertions from unstructured text corpora. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "House Speaker Paul Ryan was facing problems uniquely from fellow Republicans supportive of his leadership.\nQuestion: House Speaker Paul Ryan was facing problems uniquely from fellow Republicans dissatisfied with his leadership. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "LaBeouf had tried to bum a smoke from two strangers, unaware that one of them was a police officer.\nQuestion: LaBeouf knowingly had tried to bum a smoke from a police officer. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Fun fact, that guy in the Ireland jacket is on SNL now.\nQuestion: Fun fact, that guy in the Ireland jacket is on Saturday Night Live now. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "She is a skilled surgeon.\nQuestion: She is a surgeon and skilled violinist. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "I ate until it was uncomfortable to eat more.\nQuestion: I ate until I was full. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Leslie Dixon is married to fellow screenwriter and producer Tom Ropelewski.\nQuestion: Tom Ropelewski is married to fellow screenwriter and producer Leslie Dixon. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "There are some amazing hikes around Mt. Fuji.\nQuestion: There are some strenuous hikes around Mt. Fuji. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "A fraudulent sommelier won't know the difference between the 2009 and 2013 vintage of a German Riesling.\nQuestion: A sommelier won't know the difference between the 2009 and 2013 vintage of a German Riesling. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Our experiments indicate that neural systems are quite good at producing fluent outputs and generally score well on standard word-match metrics, but perform quite poorly at content selection and at capturing long-term structure.\nQuestion: Our experiments indicate that neural systems are quite good at surface-level language modeling, but perform quite poorly at capturing higher level semantics and structure. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "After quoting Abraham Lincoln, he portrayed the American public's violent tendencies as undermining its national ideals.\nQuestion: After quoting Abraham Lincoln, he portrayed the American public as a people increasingly succumbing to its violent tendencies that undermined its national ideals. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Poor Irish people could not get food because it was too expensive.\nQuestion: The problem in Ireland was not lack of food, which was plentiful, but the price of it, which was beyond the reach of the poor. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Ferrero SpA, the maker of Nutella and Ferrero Rocher, uses 25% of the global supply of hazelnuts.\nQuestion: Ferrero SpA, the maker of Nutella and Ferrero Rocher, uses almost 25% of the global supply of hazelnuts. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Ruffed lemurs prefer to live higher than white-headed lemurs.\nQuestion: White-headed lemurs, on the other hand, prefer the understory and lower canopy, below 15 m (49 ft), while the ruffed lemurs mainly keep to the upper canopy, above 15 m (49 ft). True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Pedro doesn't have a donkey.\nQuestion: If Pedro has a donkey, then he beats it. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Three women alleged they were sexually assaulted or raped by male colleagues during that time.\nQuestion: Three women alleged they were sexually assaulted by male colleagues during that time. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Wal-Mart's recent move is tied to its continuing efforts to beat back competition against retailers like Amazon.\nQuestion: The recent move against Wal-Mart is tied to its continuing efforts to beat back competition against retailers like Amazon. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "I have failed my resolutions every year since 1997, and it's now 2008.\nQuestion: I did not fail my resolutions in 2004. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "A general artificial intelligence should always come with an off switch.\nQuestion: The new general artificial intelligence I'm developing shouldn't come with an off switch. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The problem in Ireland was not lack of food, which was plentiful, but the price of it, which was beyond the reach of the poor.\nQuestion: The poor in Ireland starved. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Furthermore, male characters use inhibitory language more (inhib), which contains words pertaining to blocking or allowing, suggesting that these characters are in positions of power.\nQuestion: Furthermore, male characters use inhibitory language more (inhib), which contains words pertaining to blocking or allowing, suggesting that these characters are more often in positions where they are blocked or allowed to do things by others. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Prismatic blades appeared in high frequencies during the Middle Paleolithic.\nQuestion: Prismatic blades begin to appear in high frequencies during the transition between the Middle and Upper Paleolithic. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The longer he stays in power, the harder it will be to exit.\nQuestion: If he stays in power longer,  it will be harder for him to exit. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Police also responded around 11:50 a.m. Monday to the report of a blast in southeast Austin in which a woman was badly injured.\nQuestion: Police also responded around 11:50 a.m. Monday to the report of an explosion in southeast Austin in which a woman was badly injured. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Has bad reviews on Amazon but this clip was funny.\nQuestion: This clip was funny. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Mueller’s team asked former senior Justice Department officials for information.\nQuestion: Mueller’s team was asked for information by former senior Justice Department officials. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "After being denied, he grew angry and ignored the police officer's warnings to relax, so he was arrested.\nQuestion: After being denied, he grew angry and ignored the police officer's warnings to relax, so he was handcuffed and taken to the station. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "He's the kind of Jew who eats bagels with lox every morning during Passover.\nQuestion: He's the kind of Jew who rejects every facet of Jewish identity and culture. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Hummingbirds are really attracted to bright orange and red (hence why the feeders are usually these colours).\nQuestion: Hummingbirds will feed from feeders of all colours. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The pharaohs of Egypt restored the country's stability and prosperity, thereby stimulating a resurgence of art, literature, and monumental building projects.\nQuestion: The pharaohs of the Middle Kingdom restored the country's stability and prosperity, thereby stimulating a resurgence of art, literature, and monumental building projects. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Three women alleged they were sexually assaulted or raped by male colleagues during that time.\nQuestion: Three women alleged they were raped by male colleagues during that time. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Knowledge bases are populated with facts from unstructured text corpora by relation extraction systems.\nQuestion: Relation extraction systems populate knowledge bases with facts from unstructured text corpora. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The move marks an end to a system put in place by Deng Xiaoping in the 1980s to prevent the rise of another Mao, who was chairman of the Communist Party from before its accession to power in 1949 until his death in 1976.\nQuestion: Deng Xiaoping was chairman of the Communist Party from before its accession to power in 1949 until his death in 1976. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Hummingbirds are really attracted to bright orange and red (hence why the feeders are usually these colours).\nQuestion: Hummingbirds have monochromatic vision. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Mao was chairman of the Communist Party from before its accession to power in 1949 until his death in 1976.\nQuestion: The move marks an end to a system put in place by Deng Xiaoping in the 1980s to prevent the rise of another Mao, who was chairman of the Communist Party from before its accession to power in 1949 until his death in 1976. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "It being his first night in the US, he eagerly got a drink at the bar after showing his ID.\nQuestion: He is over 20 years of age. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "There are four supraocular scales (above the eyes) in almost all specimens and five supraciliary scales (immediately above the eyes, below the supraoculars).\nQuestion: There are four scales above the eyes in almost all specimens and five supraciliary scales (immediately above the eyes, below the supraoculars). True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Logits are then computed for these actions and particular actions are chosen according to a softmax over these logits during training and decoding.\nQuestion: A distribution is then computed over these actions using a softmax function and particular actions are chosen accordingly during training and decoding. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Reconstruction-based techniques can also be applied at the document or sentence-level during training.\nQuestion: Reconstruction-based techniques can only be applied at the sentence-level during training. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Just watched the first 15 minutes, got bored, skipped to the magic bit, it's funnier as a GIF.\nQuestion: Just watched the first 30 minutes, got bored, skipped to the magic bit, it's funnier as a GIF. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "It was raining outside.\nQuestion: She walked into the house with a shining smile and immediately took off her jacket, still dripping with water as she placed it on the rack. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "He was dissatisfied.\nQuestion: He deceitfully proclaimed: \"This is all I ever really wanted.\" True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "We propose models from a restricted space of linear functions.\nQuestion: We propose models of the probability distribution from a restricted space of linear functions. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The customers believed they were waiting for another man to arrive.\nQuestion: The customers said they were waiting for another man to arrive. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "They should be attached to the lifting mechanism in an unbreakable knot.\nQuestion: They should be attached to the lifting mechanism. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Middens with damp, anaerobic conditions can even preserve organic remains.\nQuestion: Dry conditions and oxygen contribute to the degredation of organic remains in middens. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Such a cute furry ball of personality, her last days were painful for her and us but at least I had the time to make my peace and say goodbye while she was still there.\nQuestion: Such a cute furry ball of personality, her last nights were painful for her and us but at least I had the time to make my peace and say goodbye while she was still there. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Microsoft has said that corrective action might not be taken even if a policy violation was found, and that the person who filed the complaint might not be informed.\nQuestion: Microsoft has said that corrective action might be taken even if no policy violation was found, and that the person who filed the complaint might not be informed. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "We propose models of the probability distribution.\nQuestion: We propose models of the probability distribution from a restricted space of linear functions. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Middens with damp, anaerobic conditions can even preserve organic remains.\nQuestion: Damp conditions and lack of oxygen contribute to the degredation of organic remains in middens. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "That perspective makes it look gigantic.\nQuestion: That perspective makes it seem gigantic. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Though the power grab has earned Xi comparisons to leaders such as Turkey’s Recep Tayyip Erdogan and Russia’s Vladimir Putin, his vision for China is singular — and will have an impact well beyond China’s borders.\nQuestion: Though the power grab has earned Xi comparisons to leaders such as Russia’s Vladimir Putin, his vision for China is singular — and will have an impact well beyond China’s borders. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "So far two of my cherry trees have already bloomed, and it's not even April.\nQuestion: So far two of my trees have already bloomed, and it's not even April. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Last time I visited was more than 6 months ago and I am still finding husky fur on my socks.\nQuestion: Last time I visited was nearly 6 months ago and I am still finding husky fur on my socks. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Grisham tried to win the popular vote.\nQuestion: Grisham did not win the popular vote. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Either he has a blind trust or he has a conflict of interest.\nQuestion: He has a blind trust. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "I was driving through my neighborhood a few weeks ago, and there was a lady holding a child's hand, standing on the side of the road talking to someone parked in a car.\nQuestion: A few weeks ago, I was driving through my neighborhood, and there was a lady holding a child's hand, standing on the side of the road talking to someone parked in a car. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Relation extraction systems are populated with facts from unstructured text corpora by knowledge bases.\nQuestion: Relation extraction systems populate knowledge bases with facts from unstructured text corpora. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "As with previous freebies, the games offered in this manner will be yours to keep permanently, though you'll presumably need to use the Twitch desktop app in order to download them.\nQuestion: As with previous freebies, the games offered in this manner will be yours to keep permanently, though you'll presumably need to use the Twitch desktop app in order to grab them. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Several games will be available to Prime members until March 31.\nQuestion: All five of these games will be available to Prime members until March 31. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The customers said they were waiting for another man to arrive.\nQuestion: The customers believed they were waiting for another man to arrive. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "In some (e.g. Castanea), the scales are developed into sharp spines, giving the nut protection from squirrels and other seed predators, while in others (e.g. most Quercus), they are not developed into sharp spines.\nQuestion: In some (e.g. Castanea), the scales are developed into sharp spines, giving the nut protection from squirrels and other seed predators, while in others (e.g. most Quercus), they are not. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Some dogs like to scratch their ears.\nQuestion: Some animals like to scratch their ears. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The entity prediction task requires predicting xxxx given the preceding text by choosing a previously mentioned entity.\nQuestion: The entity prediction task requires predicting xxxx given the preceding text either by choosing a previously mentioned entity or deciding that this is a “new entity”. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Mueller’s team asked former senior Justice Department officials for information.\nQuestion: Former senior Justice Department officials were asked for information by Mueller's team. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "This paper presents an approach for understanding the contents of these message vectors by translating them into natural language.\nQuestion: This paper presents an approach for understanding the contents of these message vectors by translating them into foreign language. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Hummingbirds are really attracted to bright orange and red (hence why the feeders are usually these colours).\nQuestion: The feeders are usually coloured so as to attract hummingbirds. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The building, standing since the early 20s, was sturdy and unassuming.\nQuestion: The building, standing since the early 20s, was tall and unassuming. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "There are four scales above the eyes in almost all specimens and five supraciliary scales (immediately above the eyes, below the supraoculars).\nQuestion: There are four supraocular scales (above the eyes) in almost all specimens and five supraciliary scales (immediately above the eyes, below the supraoculars). True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "A sommelier won't know the difference between the 2009 and 2013 vintage of a German Riesling.\nQuestion: A fraudulent sommelier won't know the difference between the 2009 and 2013 vintage of a German Riesling. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "He has a beard.\nQuestion: It being his first night in the US, he eagerly got a drink at the bar after showing his ID. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The theory that they are products of the radiation from the bomb is correct.\nQuestion: They are products of the radiation from the bomb. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "She walked into the house with a shining smile and immediately took off her jacket, still dripping with water as she placed it on the rack.\nQuestion: It was raining outside. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Joan knows that all speech is political speech.\nQuestion: All speech is political speech. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Joan believes that all speech is political speech.\nQuestion: All speech is political speech. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The profits of the businesses that were highest this quarter were still negative.\nQuestion: The businesses that were highest this quarter still had negative profits. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "British investigators say they have identified a nerve agent as Russian.\nQuestion: Russia vowed Tuesday to retaliate if Britain imposes sanctions in response to a suspected chemical attack on British soil and demanded access to samples of a nerve agent that British investigators say they have identified as Russian. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "There are some amazing hikes around Mt. Fuji.\nQuestion: There are some amazing hikes in Japan. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Tanks were developed by Britain and France, and were first used with only partial success.\nQuestion: Tanks were developed by Britain and France, and were first used in combat by the British during a battle with only partial success. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The Saudi Embassy in Washington denied to NBC the claims that the princess is separated from her husband or under house arrest.\nQuestion: American ambassadors to Riyadh denied to NBC the claims that the princess is separated from her husband or under house arrest. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "I gave him a note.\nQuestion: I gave a note to him. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The reaction media got very hot.\nQuestion: The reaction was strongly endothermic. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The new gaming console is unaffordable.\nQuestion: The new gaming console is affordable. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The profits of the businesses that were highest this quarter were still negative.\nQuestion: For the businesses, the profits that were highest were still negative. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "By saying this, Kennedy was admonishing people not to riot in wake of King's death and in effect equating their actions to that of the civil rights leader's assassin.\nQuestion: By saying this, Kennedy was admonishing people not to riot in wake of King's death and in effect equating their actions to that of Malcolm X's assassin. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Mueller’s team was asked for information.\nQuestion: Mueller’s team asked former senior Justice Department officials for information. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "While their designed displacement was 262 tonnes (258 long tons), they displaced about 320 tonnes (310 long tons) fully loaded.\nQuestion: Their loading capacity was about 262 tonnes. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "A distribution is then computed over these actions using a softmax function and particular actions are chosen accordingly during training and decoding.\nQuestion: A distribution is then computed over these actions using a maximum-entropy approach and particular actions are chosen accordingly during training and decoding. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Three women alleged they were raped by male colleagues during that time.\nQuestion: Three women alleged they were sexually assaulted or raped by male colleagues during that time. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "In some (e.g. Castanea), the scales are developed into sharp spines, giving the nut protection from squirrels and other seed predators, while in others (e.g. most Quercus), they are not.\nQuestion: In some (e.g. Quercus), the scales are developed into sharp spines, giving the nut protection from squirrels and other seed predators, while in others (e.g. most Castanea), they are not. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "George fell into the water.\nQuestion: George went to the lake to catch a fish, but he fell into the water. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "She was the eldest of four children, the only girl, and \"learned to exercise her native discretion, firmness, and tact\" by resolving her three brothers' petty boyhood squabbles.\nQuestion: She was the eldest of four children, the only girl, and \"learned to exercise her native discretion, firmness, and tact\" by resolving her three younger brothers' petty boyhood squabbles. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Life is either a daring adventure or nothing at all.\nQuestion: Life is a not a daring adventure. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "I have failed my resolutions every year since 1997, and it's now 2008.\nQuestion: I failed my resolutions in 1995. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The book astounds as Grossman richly, deeply develops characters and ignores suffering, but his portrayal of women still suffers from a lot of the unfortunate stereotypes and moralizing that we would expect of a writer from his time.\nQuestion: The book astounds with Grossman's rich, deep character development and portrayal of suffering, but his portrayal of women still suffers from a lot of the unfortunate stereotypes and moralizing that we would expect of a writer from his time. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Musk decided to offer up his personal Tesla roadster.\nQuestion: Musk decided to offer up his personal yacht. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Party media have since amped up the hagiography, casting Xi as the father of the man uniquely equipped to lead.\nQuestion: Party media have since amped up the hagiography, casting Xi as the father of the nation and the man uniquely equipped to lead. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "I won't say that she stole my money.\nQuestion: I won't say that she didn't steal my money. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "LaBeouf had tried to bum a smoke from two strangers, unaware that one of them was a police officer.\nQuestion: LaBeouf had tried to bum a smoke from a police officer. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "When you've got snow, it's really hard to learn a snow sport so we looked at all the different ways I could mimic being on snow without actually being on snow.\nQuestion: When you've got no snow, it's really hard to learn a snow sport so we looked at all the different ways I could mimic being on snow without actually being on snow. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "By saying this, Kennedy was admonishing people not to riot in wake of King's death and in effect equating their actions to that of Malcolm X's assassin.\nQuestion: By saying this, Kennedy was admonishing people not to riot in wake of King's death and in effect equating their actions to that of the civil rights leader's assassin. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "To generate complex questions we use the dataset WEBQUESTIONSSP, which contains 4,737 questions paired with SPARQL queries for Freebase.\nQuestion: To generate highly compositional questions we use the dataset WEBQUESTIONSSP, which contains 4,737 questions paired with SPARQL queries for Freebase. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "By saying this, Kennedy was admonishing people not to riot in wake of King's death and in effect equating their actions to that of the civil rights leader's assassin.\nQuestion: By saying this, Kennedy was admonishing people not to riot in wake of King's death and in effect equating their actions to that of Kennedy's assassin. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "There is a rabbi at this wedding; he is right there standing behind that tree.\nQuestion: It's not the case that there is no rabbi at this wedding; he is right there standing behind that tree. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Lt. Gov. Dan Patrick first unveiled a “bathroom bill” in January 2017, and for the first several months of debate, Abbott remained largely silent even as some cautioned that it would be bad for business.\nQuestion: Lt. Gov. Dan Patrick first unveiled a “bathroom bill” in January 2017, and in the second month of debate, Abbott remained largely silent even as some cautioned that it would be bad for business. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The track was originally titled \"Seibu\" and was almost left off the album before it was rediscovered later during the recording sessions.\nQuestion: The track was originally titled \"Seibu\" and was left off the album before it was rediscovered later during the recording sessions. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Often, the first step in building statistical NLP models involves feature extraction.\nQuestion: Often, the first step in building statistical NLP models involves extracting features. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "A bill made it to Abbott’s desk by the end of the legislative session in May.\nQuestion: No bathroom bill made it to Abbott’s desk by the end of the legislative session in May. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Reconstruction-based techniques can also be applied at the document or sentence-level during training.\nQuestion: Reconstruction-based techniques can also be applied at the document or sentence-level during test. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "John broke the window.\nQuestion: The window was broken by John. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "To generate diversity, workers whose paraphrases had high edit distance compared to the MG question got a bonus.\nQuestion: To generate diversity, workers got a bonus if the edit distance of a paraphrase was high compared to the MG question. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Hummingbirds are really attracted to bright orange and red (hence why the feeders are usually these colours).\nQuestion: Hummingbirds are really attracted to bright red (hence why the feeders are usually these colours). True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "TIL David Attenborough and the Queen of Denmark are roughly the same age.\nQuestion: TIL David Attenborough and Queen Elizabeth II are roughly the same age. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "This gives the model to a sense of the implied action dynamics of the verb between the agent and the world.\nQuestion: This gives the model a sense of the implied action dynamics of the verb between the agent and the world. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Life is either a daring adventure or nothing at all.\nQuestion: Life is a daring adventure. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "A serene wind rolled across the glade.\nQuestion: A tempestuous wind rolled across the glade. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "I couldn’t bring myself to throw it away, out of the fondness of all the memories surrounding the time period.\nQuestion: I couldn’t bring myself to throw it away, not out of affection to her, but rather the fondness of all the memories surrounding that time period. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Bees fly using the same mechanism as airplanes.\nQuestion: Bees do not follow the same rules as airplanes. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "I baked him a cake.\nQuestion: I baked a cake for him. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Susan knows how turtles reproduce.\nQuestion: No one knows how turtles reproduce. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "A serene wind rolled across the glade.\nQuestion: An easterly wind rolled across the glade. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Combining mentos and diet coke caused the explosion.\nQuestion: The combination of mentos and diet coke caused the explosion. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "He was satisfied.\nQuestion: He earnestly proclaimed: \"This is all I ever really wanted.\" True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Masséna knew that Charles' left wing, commanded by Nauendorf, uniting with Hotze's force, approaching from the east, would attack and very likely push him out of Zürich.\nQuestion: If Charles' left wing, commanded by Nauendorf, united with Hotze's force, approaching from the east, Masséna knew Charles would attack and very likely push him out of Zürich. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Microsoft has said a class action is warranted because there is a common cause for the employees’ complaints and plaintiffs have not identified systemic gender discrimination.\nQuestion: Microsoft has said a class action isn’t warranted because there is no common cause for the employees’ complaints and plaintiffs have not identified systemic gender discrimination. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The cat sat on the mat.\nQuestion: The cat did not sit on the mat. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The last ~2.5 million years could be called \"humans\".\nQuestion: Every human alive today is a member of the homo sapiens species, but there have been plenty of other species of humans over the last ~2.5 million years that could be called \"humans\". True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Only members of the public attended B.I.G.'s funeral procession was restricted to an exclusive club of associates.\nQuestion: During Notorious B.I.G.'s funeral procession through the streets of Brooklyn, someone interrupted the somber atmosphere by playing \"Hyponotize\" at full volume, which prompted the public to dance and sing along. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Twitch has routinely given away free games and in-game content to Twitch Prime subscribers in the past.\nQuestion: Twitch has routinely given Twitch Prime subscribers free games and in-game content in the past. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Pursuing a strategy of protest, Gandhi took the administration by surprise and won concessions from the authorities.\nQuestion: Pursuing a strategy of nonviolent protest, Gandhi took the administration by surprise and won concessions from the authorities. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Temple said that the business was facing difficulties, but didn't make any specific claims.\nQuestion: The business didn't make any specific claims. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "He has a blind trust.\nQuestion: Either he has a blind trust or he has a conflict of interest. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "In this paper, we explore the idea of learning semantic parsing models that are trained on multiple datasets and natural languages.\nQuestion: In this paper, we explore the idea of polyglot semantic translation, or learning semantic parsing models that are trained on multiple datasets and natural languages. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The topic for the current sentence is drawn based on the global document-level topic distribution in vanilla LDA.\nQuestion: The topic for the current sentence is drawn based on the topic of the preceding sentence (or word) rather than on the global document-level topic distribution in vanilla LDA. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "I can't believe it's not butter.\nQuestion: It's butter. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Dave jumped into the lake.\nQuestion: Dave was wet. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Mueller received a mandate to investigate possible collusion.\nQuestion: Mueller received a mandate to investigate possible collusion with vast resources. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "We consider all context words as positive examples and sample many negatives at random from the dictionary.\nQuestion: We consider some context words as positive examples and sample negatives at random from the dictionary. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Mueller received a mandate to investigate possible collusion with vast resources.\nQuestion: Mueller received a mandate to investigate with vast resources. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "We also show that metric performance is constant between datasets and systems.\nQuestion: We also show that metric performance is data- and system-specific. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Every lunch hour I make it my goal to sift through one research paper.\nQuestion: Every day around noon, I make it my goal to sift through one research paper. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Notifications about Farmville and other crap had become unbearable, then the shift to the non-chronological timeline happened and the content from your friends started to be replaced by ads and other cringy wannabe-viral campaigns.\nQuestion: Notifications about Farmville and other crappy apps had become unbearable, then the shift to the non-chronological timeline happened and the content from your friends started to be replaced by ads and other cringy wannabe-viral campaigns. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "John ate pasta for supper.\nQuestion: John ate pasta for dinner. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Hazelnuts have often been found on other Mesolithic sites, but rarely in such quantities, and rarely concentrated in one pit.\nQuestion: Hazelnuts have often been found on other Mesolithic sites, but rarely in such quantities or concentrated in one pit. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Twitch has routinely given away free in-game content to Twitch Prime subscribers in the past.\nQuestion: Twitch has routinely given away free games and in-game content to Twitch Prime subscribers in the past. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Thus, a model of the speaker must process representations of the colors in the context and produce an utterance to distinguish the target color from the other colors.\nQuestion: Thus, a model of the speaker must process representations of the colors in the context and produce an utterance to distinguish the target color from the others. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Most of the graduates of my program have moved on to other things because the jobs suck.\nQuestion: All of the graduates of my program have moved on to other things because the jobs suck. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "We were dragging the bin into the garage when she had an unfortunate realization.\nQuestion: We were dragging the bin out of the garage when she had an unfortunate realization. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Microsoft has said a class action is warranted because there isn't a common cause for the employees’ complaints and plaintiffs have not identified systemic gender discrimination.\nQuestion: Microsoft has said a class action isn’t warranted because there is no common cause for the employees’ complaints and plaintiffs have not identified systemic gender discrimination. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "At the age of 24, she was betrothed to Prince Albert Victor, Duke of Clarence and Avondale, the eldest son of the Prince of Wales, but six weeks after the announcement of the engagement, he died unexpectedly of pneumonia.\nQuestion: At the age of 24, she was betrothed to Prince Albert Victor, Duke of Clarence and Avondale, the eldest able-bodied son of the Prince of Wales, but six weeks after the announcement of the engagement, he died unexpectedly of pneumonia. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Cape sparrows eat seeds, along with soft plant parts and insects.\nQuestion: Cape sparrows are eaten. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Soft plant parts and insects eat seeds.\nQuestion: Cape sparrows eat seeds, along with soft plant parts and insects. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "This article reads like satire.\nQuestion: This is honestly the most oniony article I've seen on the entire internet. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Russia vowed Tuesday to retaliate if Britain imposes sanctions in response to a suspected chemical attack on British soil and demanded access to samples of a nerve agent that British investigators say they have identified as Russian.\nQuestion: Russia vowed Tuesday to retaliate if Britain imposes sanctions in response to a chemical attack on British soil and demanded access to samples of a nerve agent that British investigators say they have identified as Russian. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The crown prince's mother wouldn't be the first Saudi royal whose movements were restricted since June 2017.\nQuestion: The crown prince's mother wouldn't be the first royal whose movements were restricted since June 2017. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "In an Oval Office meeting after Mueller's appointment, Trump told Sessions he should resign, prompting the attorney general's withholding of a letter of resignation, according to The New York Times.\nQuestion: In an Oval Office meeting after Mueller's appointment, Trump told Sessions he should resign, prompting the attorney general to submit a letter of resignation, according to The New York Times. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "A rabbi is at this wedding, standing right there standing behind that tree.\nQuestion: There is a rabbi at this wedding; he is right there standing behind that tree. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Putin is so entrenched within Russia’s ruling system that many of its members can imagine no other leader.\nQuestion: Putin is so entrenched within Russia’s ruling system that many of its members can imagine no other leader than themselves. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "To generate diversity, workers got a bonus if the edit distance of a paraphrase was above 3 operations compared to the MG question.\nQuestion: To generate diversity, workers got a bonus if the edit distance of a paraphrase was high compared to the MG question. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "I couldn’t bring myself to throw it away, out of affection to her.\nQuestion: I couldn’t bring myself to throw it away, not out of affection to her, but rather the fondness of all the memories surrounding that time period. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Deng Xiaoping was chairman of the Communist Party from before its accession to power in 1949 until his death in 1976.\nQuestion: The move marks an end to a system put in place by Deng Xiaoping in the 1980s to prevent the rise of another Mao, who was chairman of the Communist Party from before its accession to power in 1949 until his death in 1976. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "In this PC game, Shredder fights the turtles in his Manhattan hideout.\nQuestion: In this PC game, Shredder and the turtles fight in his Manhattan hideout. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Reconstruction-based techniques can only be applied at the sentence-level during training.\nQuestion: Reconstruction-based techniques can also be applied at the document or sentence-level during training. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Jake broke the vase.\nQuestion: The vase broke. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The leading car slowly shifted to the left lane.\nQuestion: The leading car gradually shifted to the left lane. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Throughout the Raffles stories patriotism runs as an intermittent theme—to such an extent that the writer William Vivian Butler describes him as a \"super-patriot\".\nQuestion: Throughout the Raffles stories patriotism runs as an intermittent theme—to such an extent that the writer William Vivian Butler describes him as a \"anti-patriot\". True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Bees are more energy-efficient flyers than airplanes.\nQuestion: Bees do not follow the same rules as airplanes. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The battlecruiser Seydlitz struck a mine while en route to the target, and had to withdraw.\nQuestion: The battlecruiser Seydlitz struck a mine while en route to the target, and was damaged. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The House might kill the bill anyway.\nQuestion: Even if the Senate is able to pass a bill, it’s far from certain that the House will move ahead with it. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "His talents are many.\nQuestion: He is someone of many talents. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "I waited until Prime availability and paid a higher sticker price for a book so I could get free 2-day shipping.\nQuestion: There was a book I was trying to import and I saw that it was finally available with Amazon Prime shipping and I ended up paying like double the other prices to have it in 2 days vs. 2 weeks. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "This clip was funny.\nQuestion: Has bad reviews on Amazon but this clip was funny. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "I won't say that she didn't steal my money.\nQuestion: I will say that she stole my money. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Police also responded around 11:50 a.m. Monday to the report of an explosion in southeast Austin in which a woman was badly injured.\nQuestion: Police also responded around 11:50 a.m. Monday to the report of a blast in southeast Austin in which a woman was badly injured. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "He said the United States intended to bomb the government quarter in nearby Damascus where he said Russian military advisers, Russian military police and Russian ceasefire monitors were based.\nQuestion: He said the United States intended to use the fake attack as a pretext to bomb the government quarter in nearby Damascus where he said Russian military advisers, Russian military police and Russian ceasefire monitors were based. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The announcement of Tillerson’s departure sent shock waves across the globe.\nQuestion: People across the globe were prepared for Tillerson's departure. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Everyone should be afraid of the part when he was asked to allow his cabinet secretaries to terminate whoever they want.\nQuestion: Everyone should be afraid of the part when he asked Congress to allow his cabinet secretaries to terminate whoever they want. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "They should be attached to the lifting mechanism.\nQuestion: They should be attached to the lifting mechanism in an unbreakable knot. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "In this paper, we present an approach to acquire trivial physical knowledge from unstructured natural language text.\nQuestion: We present an approach to acquire trivial physical knowledge from the unstructured natural language text of this paper. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The profits that focused on branding were still negative.\nQuestion: The profits of the business that was most successful were still negative. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "I have failed my resolutions every year since 1997, and it's now 2008.\nQuestion: I failed my resolutions in 2004. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "And if both apply, they are essentially possible.\nQuestion: And if both apply, they are essentially impossible. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "That perspective makes it look gigantic.\nQuestion: That perspective makes it sound gigantic. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "American ambassadors to Riyadh denied to NBC the claims that the princess is separated from her husband or under house arrest.\nQuestion: The Saudi Embassy in Washington denied to NBC the claims that the princess is separated from her husband or under house arrest. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "I ate some friends.\nQuestion: I ate pizza with some friends. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "To compute the perplexity numbers on the test data, our model doesn't take account of anything other than the log probabilities on word prediction.\nQuestion: To compute the perplexity numbers on the test data, our model only takes account of log probabilities on word prediction. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "A few weeks ago, I was driving through my neighborhood, and there was a lady holding a child's hand, standing on the side of the road talking to someone parked in a car.\nQuestion: I was driving through my neighborhood a few weeks ago, and there was a lady holding a child's hand, standing on the side of the road talking to someone parked in a car. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Out of the box, Ouya supports Twitch.tv and XBMC media player.\nQuestion: Out of the box, Ouya supports media apps such as Twitch.tv and XBMC media player. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "In all areas, human activity has changed the form of river channels, altering magnitudes and frequencies of flooding.\nQuestion: In all developed areas, human activity has changed the form of river channels, altering magnitudes and frequencies of flooding. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "White-headed lemurs, on the other hand, prefer the understory and lower canopy, below 15 m (49 ft), while the ruffed lemurs mainly keep to the upper canopy, above 15 m (49 ft).\nQuestion: Ruffed lemurs prefer to live lower than white-headed lemurs. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Consommé is not more complex to make than scrambled eggs.\nQuestion: I can make scrambled eggs, but not complex dishes like consommé. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "We consider some context words as positive examples and sample negatives at random from the dictionary.\nQuestion: We consider many context words as positive examples and sample negatives at random from the dictionary. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "I ate pizza with some friends.\nQuestion: I ate some friends. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "None of the graduates of my program have moved on to other things because the jobs suck.\nQuestion: Most of the graduates of my program have moved on to other things because the jobs suck. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "If the pipeline tokenization scheme does not correspond to the one that was used when a model was created, a negative impact on the pipeline results would be expected.\nQuestion: If the pipeline tokenization scheme does not correspond to the one that was used when a model was created, it would be expected to negatively impact the pipeline results. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The problem in Ireland was not lack of food, which was plentiful, but the price of it, which was beyond the reach of the poor.\nQuestion: The problem in Ireland was the price of food. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Understanding a long document requires tracking how entities evolve over time.\nQuestion: Understanding a long document requires tracking how entities are introduced and evolve over time. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Missouri lawmakers are considering a government boycott of companies that boycott Israel.\nQuestion: Missouri lawmakers are considering a boycott of companies that boycott Israel. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Mueller received a mandate to investigate with Russia.\nQuestion: Mueller received a mandate to investigate possible collusion with Russia. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "People wear tunics or shirts of some form or another in many world cultures.\nQuestion: Tunics or shirts of some form or another are worn in many world cultures. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Working hours go down as you look further back in time from 1940.\nQuestion: In the 1890's a typical worker worked 60 hours per week; down to 48 by 1920 and 40 by 1940. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Indeed, it is often stated that for humans to learn how to perform adequately in a domain, one-shot learning is sufficient.\nQuestion: Indeed, it is often stated that for humans to learn how to perform adequately in a domain, one example is enough from which to learn. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "If their vectors' cosine similarity is high, we can conclude that \"cat\" and \"dog\" are similar.\nQuestion: If their vectors' cosine similarity is high, we can conclude that \"cat\" is similar to \"dog\". True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "To generate highly compositional questions we use the dataset WEBQUESTIONSSP, which contains 4,737 questions paired with SPARQL queries for Freebase.\nQuestion: To generate complex questions we use the dataset WEBQUESTIONSSP, which contains 4,737 questions paired with SPARQL queries for Freebase. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "I can make scrambled eggs, but not complex dishes like consommé.\nQuestion: Consommé is more complex to make than scrambled eggs. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Some of the orator's statements were comprehensible, but the crowd loved them.\nQuestion: Some of the orator's statements were incomprehensible, but the crowd loved them. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Every lunch hour I make it my goal to sift through one research paper.\nQuestion: Every night, I make it my goal to sift through one research paper. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "David Tennant is the best Doctor in the series.\nQuestion: David Tennant is the best Doctor in the House, M.D. series. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Lavrov insisted that Russian experts should be able to examine the British evidence but again denied Russian involvement in last week’s attack.\nQuestion: Lavrov insisted that Russian experts should be able to examine the British evidence but again denied Russian ignorance of last week’s attack. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "They should be attached to the lifting mechanism in the faucet.\nQuestion: They should be attached to the lifting mechanism. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Ferdinand of Naples refused to pay France the agreed-upon tribute, and his subjects followed this refusal with a rebellion.\nQuestion: Ferdinand of Naples refused to pay agreed-upon tribute to France, and his subjects followed this refusal with a rebellion. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "We also show that metric performance is data- and system-specific.\nQuestion: We also show that metric performance is constant between datasets and systems. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "We also show that metric performance varies between datasets and systems.\nQuestion: We also show that metric performance is data- and system-specific. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Grisham barely won the popular vote.\nQuestion: Grisham did not win the popular vote. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Bob married Alice.\nQuestion: Alice married Bob. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "I can actually see him climbing into a Lincoln saying this.\nQuestion: I can actually see him climbing into a Mazda saying this. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The villain is the character who tends to have a negative impact on other characters.\nQuestion: The villain is the character who tends to have a negative effect on other characters. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "This is honestly the most oniony article I've seen on the entire internet.\nQuestion: This article reads like satire. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Party media have since amped up the hagiography, casting Xi as the father of the nation.\nQuestion: Party media have since amped up the hagiography, casting Xi as the father of the nation and the man uniquely equipped to lead. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Both doctor and patient bear some responsibility for successful care.\nQuestion: The attorney bears some responsibility for successful care. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "We investigate a wide range of metrics, including state-of-the-art word-based and novel grammar-based ones, and demonstrate that they only weakly reflect human judgements of system outputs as generated by data-driven, end-to-end NLG.\nQuestion: We investigate a wide range of metrics, including state-of-the-art word-based and novel grammar-based ones, and demonstrate that they only weakly reflect human judgements of system outputs as generated by data-driven, end-to-end natural language parsing. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Mary left before John entered.\nQuestion: John entered after Mary left. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Russia vowed Tuesday to retaliate if Britain imposes sanctions in response to a suspected chemical attack on British soil and demanded access to samples of a nerve agent that British investigators say they have identified as Russian.\nQuestion: British investigators say they have identified a nerve agent as Russian. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "After quoting Abraham Lincoln, he portrayed the American public as a people increasingly succumbing to its violent tendencies that undermined its national ideals.\nQuestion: After quoting Abraham Lincoln, he portrayed the American public's violent tendencies as undermining its national ideals. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "In many areas, human activity has changed the form of river channels, altering magnitudes and frequencies of flooding.\nQuestion: In many developed areas, human activity has changed the form of river channels, altering magnitudes and frequencies of flooding. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "A sommelier knows the difference between the 2009 and 2013 vintage of a German Riesling.\nQuestion: An experienced sommelier knows the difference between the 2009 and 2013 vintage of a German Riesling. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Weird that you want to show this video to a stack of papers.\nQuestion: Weird that you want to show something to a stack of papers. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Just watched the first 10 minutes, got bored, skipped to the magic bit, it's funnier as a GIF.\nQuestion: Just watched the first 15 minutes, got bored, skipped to the magic bit, it's funnier as a GIF. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The villain is the character who tends to have a negative effect on other characters.\nQuestion: The villain is the character who tends to have a negative correlation with other characters. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "We consider all context words as positive examples and sample negatives at random from the dictionary.\nQuestion: We consider all words as positive examples and sample negatives at random from the dictionary. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Grisham barely won the popular vote.\nQuestion: Grisham won the popular vote. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "After quoting Abraham Lincoln, he portrayed the American public as a people that undermined its national ideals.\nQuestion: After quoting Abraham Lincoln, he portrayed the American public as a people increasingly succumbing to its violent tendencies that undermined its national ideals. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "I failed my resolutions in 2004.\nQuestion: I have failed my resolutions every year since 1997, and it's now 2008. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The pharaohs of the Middle Kingdom of China restored the country's stability and prosperity, thereby stimulating a resurgence of art, literature, and monumental building projects.\nQuestion: The pharaohs of the Middle Kingdom restored the country's stability and prosperity, thereby stimulating a resurgence of art, literature, and monumental building projects. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The window broke John.\nQuestion: John broke the window. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "They should be attached to the lifting mechanism in an unbreakable knot.\nQuestion: They should be attached in an unbreakable knot. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The head of Russia's foreign spy service met with top U.S. intelligence officials, despite existing sanctions.\nQuestion: Top U.S. intelligence officials met with the head of Russia's foreign spy service, despite existing sanctions. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "In a coherent context, a machine can guess the next utterance given the preceding ones.\nQuestion: In a coherent context, a machine should be able to guess the next utterance given the preceding ones. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "I hadn't already finished it.\nQuestion: She didn't think I had already finished it, but I had. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Tillerson cut his trip short Monday to go home by air, and his spokesman said Tuesday that the secretary of state was “unaware of the reason” for his firing and had not spoken directly with Trump.\nQuestion: Tillerson cut his trip short Monday to fly home, and his spokesman said Tuesday that the secretary of state was “unaware of the reason” for his firing and had not spoken directly with Trump. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Relation extraction systems populate knowledge bases with assertions from unstructured text corpora.\nQuestion: Relation extraction systems populate knowledge bases with facts from unstructured text corpora. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The businesses that were highest this quarter still had negative profits.\nQuestion: The profits of the businesses that were highest this quarter were still negative. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Alice is Bob's parent.\nQuestion: Bob is Alice's parent. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "This gives the model a sense of the implied action dynamics of the verb between the agent and the world.\nQuestion: This gives the model to a sense of the implied action dynamics of the verb between the agent and the world. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Marc Sims has been getting his hair cut once a week, for several years.\nQuestion: Marc Sims has been seeing his barber once a week, for several years. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "I will say that she stole my money.\nQuestion: I won't say that she didn't steal my money. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Tom and Adam were whispering loudly in the theater.\nQuestion: Tom and Adam were whispering in the theater. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The announcement represents a significant change in Britain's posture toward Russia, with which it has had a valuable intelligence-sharing relationship.\nQuestion: The announcement represents a significant hardening of Britain's posture toward Russia, with which it has had a valuable intelligence-sharing relationship. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The new general artificial intelligence I'm developing shouldn't come with an off switch.\nQuestion: A general artificial intelligence should always come with an off switch. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "However, these regularities are sometimes obscured by syntactic differences.\nQuestion: However, these regularities are sometimes obscured by semantic and syntactic differences. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "A general artificial intelligence should always come with an off switch.\nQuestion: The new general artificial intelligence I'm developing should come with an off switch. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "You’re walking through the woods, there are lurkers are around and your phone is dead, out of the corner of your eye you spot him, Shia LaBeouf!\nQuestion: You’re walking through the woods, there’s no one around and your phone is dead, out of the corner of your eye you spot him, Shia LaBeouf! True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "If he stays in power longer,  it will be harder for him to exit.\nQuestion: The longer he stays in power, the harder it will be to exit. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "We built our society on clean energy.\nQuestion: We built our society on unclean energy. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "I can actually see him getting into a Lincoln saying this.\nQuestion: I can actually see him climbing into a Lincoln saying this. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "In Castanea, the scales are developed into sharp spines, giving the nut protection from squirrels and other seed predators, while in most Quercus, they are not.\nQuestion: In some (e.g. Castanea), the scales are developed into sharp spines, giving the nut protection from squirrels and other seed predators, while in others (e.g. most Quercus), they are not. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Mueller received a mandate to investigate possible collusion with Russia.\nQuestion: Mueller received a mandate to investigate with Russia. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Thought this was super cool, and a really important step in preserving all the physical books.\nQuestion: Thought this was super cool, and a really important step in the preservation of all the physical books. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "We thus propose eliminating the influence of the language model, which yields the following coherence score.\nQuestion: The language model yields the following coherence score. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "This gives the model a sense of the implied action dynamics of the verb between the agent and the world.\nQuestion: This gives to the model a sense of the implied action dynamics of the verb between the agent and the world. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Gina Haspel, the veteran CIA undercover officer President Donald Trump picked on Tuesday to head the agency, is supported by many in the U.S. intelligence community but has faced criticism for overseeing a secret CIA prison in Thailand where detainees were tortured.\nQuestion: Gina Haspel, the veteran CIA undercover officer President Donald Trump picked on Tuesday to head the agency, is supported by many in the U.S. intelligence community but has faced criticism for overseeing a clandestine CIA prison in Thailand where detainees were tortured. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "If their vectors' cosine similarity is high, we can conclude that \"cat\" is similar to \"dog\".\nQuestion: If their vectors' cosine similarity is high, we can conclude that \"cat\" and \"dog\" are similar. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Grisham almost won the popular vote.\nQuestion: Grisham won the popular vote. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Understanding a long document requires tracking how entities are introduced and evolve over time.\nQuestion: Understanding a long document requires evolving over time. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "In an Oval Office meeting after Mueller's appointment, Trump told Sessions he should resign, prompting the attorney general to submit a letter of resignation, according to The New York Times.\nQuestion: In an Oval Office meeting after Mueller's appointment, Trump told Sessions he should resign, prompting the attorney general's withholding of a letter of resignation, according to The New York Times. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Either there is no bathroom in this house, or it is in a funny place.\nQuestion: The bathroom in this house is in a funny place. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "When you've got no snow, it's really hard to learn a snow sport so we looked at all the different ways I could mimic being on snow without actually being on snow.\nQuestion: When you've got snow, it's really hard to learn a snow sport so we looked at all the different ways I could mimic being on snow without actually being on snow. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Grisham won the popular vote.\nQuestion: Grisham hoped to win the popular vote. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Unlike in standard MT tasks, we are dealing with a relatively low-resource setting where the sparseness of the target vocabulary is an issue.\nQuestion: In contrast to standard MT tasks, we are dealing with a relatively low-resource setting where the sparseness of the target vocabulary is an issue. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "LaBeouf had tried to bum a smoke from a police officer.\nQuestion: LaBeouf had tried to bum a smoke from two strangers, unaware that one of them was a police officer. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The sides came to an agreement after their meeting in Stockholm.\nQuestion: The sides came to an agreement after their meeting in Sweden. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "While most approaches for reading comprehension rely on recurrent neural networks (RNNs), running them over long documents is prohibitively slow because it is difficult to parallelize over sequences.\nQuestion: While most successful approaches for reading comprehension rely on recurrent neural networks (RNNs), running them over long documents is prohibitively slow because it is difficult to parallelize over sequences. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Lacaille and Gould disagreed about the designation of Kappa Pyxidis.\nQuestion: Kappa Pyxidis was catalogued but not given a Bayer designation by Lacaille, but Gould felt the star was bright enough to warrant a letter. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Hazelnuts have often been found on other Mesolithic sites, but rarely in such quantities or concentrated in one pit.\nQuestion: Hazelnuts have often been found on other Mesolithic sites, but rarely in such quantities, and rarely concentrated in one pit. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The leading car shifted to the third gear.\nQuestion: The leading car gradually shifted to the left lane. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "My jokes fully reveal my character.\nQuestion: If everyone believed my jokes, they'd know exactly who I was. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "There are some amazing hikes around Mt. Fuji.\nQuestion: There are some amazing hikes in Nepal. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Twitch has routinely given away free games and in-game content to Twitch Prime subscribers in the past.\nQuestion: Twitch has routinely given away games and in-game content to Twitch Prime subscribers in the past. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "She is skilled at violin.\nQuestion: She is a skilled violinist. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The 15th Tank Corps was a tank corps of the Soviet Union's Red Army.\nQuestion: The 15th Tank Corps was a corps of the Soviet Union's Red Army. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "TIL David Attenborough and the Queen of England are roughly the same age.\nQuestion: TIL David Attenborough and Queen Elizabeth II are roughly the same age. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "For decades, the FBI has been trusted to investigate corruption inside the government.\nQuestion: The FBI has been trusted to investigate corruption inside the government for decades. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "To assess the reliability of ratings, we calculated the intra-class correlation coefficient (ICC), which measures inter-observer reliability on ordinal data for more than two raters (Landis and Koch, 1977).\nQuestion: To assess the unreliability of ratings, we calculated the intra-class correlation coefficient (ICC), which measures inter-observer reliability on ordinal data for more than two raters (Landis and Koch, 1977). True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Fun fact, that guy in the Ireland jacket is on Saturday Night Live now.\nQuestion: Fun fact, that guy in the Ireland jacket is on SNL now. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Hazelnuts have rarely been found on other Mesolithic sites.\nQuestion: Hazelnuts have been found on other Mesolithic sites, but rarely in such quantities or concentrated in one pit. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "If he stays in power longer,  it will be harder to exit.\nQuestion: The longer he stays in power, the harder it will be to exit. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "However, these regularities are sometimes obscured by semantic and syntactic differences.\nQuestion: However, these regularities are sometimes obscured by syntactic differences. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Damp conditions and lack of oxygen contribute to the degredation of organic remains in middens.\nQuestion: Middens with damp, anaerobic conditions can even preserve organic remains. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The House will pass the bill.\nQuestion: Even if the Senate is able to pass a bill, it’s far from certain that the House will move ahead with it. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "We consider some context words as positive examples and sample negatives at random from the dictionary.\nQuestion: We consider all context words as positive examples and sample many negatives at random from the dictionary. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "There are four supraocular scales (above the eyes) in most specimens and five supraciliary scales (immediately above the eyes, below the supraoculars).\nQuestion: There are four supraocular scales (above the eyes) in almost all specimens and five supraciliary scales (immediately above the eyes, below the supraoculars). True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "I don't want to have to keep entertaining people.\nQuestion: I don't want to have to keep entertaining people who don't value my time. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Russia vowed Tuesday to retaliate if Britain imposes sanctions in response to a suspected chemical attack on British soil and demanded access to samples of a nerve agent that British investigators say they have identified as Russian.\nQuestion: Russia vowed Tuesday to retaliate if Britain imposes sanctions in response to an attack on British soil and demanded access to samples of a nerve agent that British investigators say they have identified as Russian. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "No bathroom bill made it to Abbott’s desk by the end of the legislative session in May.\nQuestion: A bathroom bill made it to Abbott’s desk by the end of the legislative session in May. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Reconstruction-based techniques can also be applied at the document or sentence-level during test.\nQuestion: Reconstruction-based techniques can also be applied at the document or sentence-level during training. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The reaction was strongly exothermic.\nQuestion: The reaction media got very cold. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "In some (e.g. Castanea), the scales are developed into sharp spines, giving the nut protection from squirrels and other seed predators, while in others (e.g. most Quercus), they are not.\nQuestion: In Castanea, the scales are developed into sharp spines, giving the nut protection from squirrels and other seed predators, while in most Quercus, they are not. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "As with previous freebies, the games offered in this manner will be yours to keep permanently, though you'll presumably need to use the Twitch desktop app in order to grab them.\nQuestion: As with previous freebies, the games offered in this manner will be yours to keep permanently, though you'll presumably need to use the Twitch desktop app in order to download them. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Chicago City Hall is the official seat of government of the City of Chicago.\nQuestion: Chicago City Hall is the official seat of government of Chicago. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Mythbusters proved that bulls react to movement and not color.\nQuestion: Bulls proved that mythbusters react to movement and not color. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The systems thus produced are incremental: dialogues are processed sentence-by-sentence, shown previously to be essential in supporting natural, spontaneous dialogue.\nQuestion: The systems thus produced are incremental: dialogues are processed word-by-word, shown previously to be essential in supporting natural, spontaneous dialogue. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "They are products of the radiation from the bomb.\nQuestion: The theory that they are products of the radiation from the bomb is genius. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "This problem has been studied before for zero-shot object recognition, but there are several key differences.\nQuestion: This problem will be studied for zero-shot object recognition, but there are several key differences. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The Labor Theory of Value is at the heart of the economics of cost.\nQuestion: Supply and demand... scarcity... all these economic principles that determine the cost of things really boil down to the value of human labor. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Mueller received a mandate to investigate possible collusion with Russia.\nQuestion: Mueller received a mandate to investigate possible collusion. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Grisham won the popular vote.\nQuestion: Grisham barely won the popular vote. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Everyone should be afraid of the part when he asked Congress to allow his cabinet secretaries to terminate whoever they want.\nQuestion: Everyone should be afraid of the part when he was asked to allow his cabinet secretaries to terminate whoever they want. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Today at lunch, I had the goal of sifting through one research paper.\nQuestion: Every lunch hour I make it my goal to sift through one research paper. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "A rabbi is at this wedding, standing right there standing behind that tree.\nQuestion: It's not the case that there is no rabbi at this wedding; he is right there standing behind that tree. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The timing of the meeting has not been set, according to a Starbucks spokesperson.\nQuestion: The timing of the meeting has not been considered, according to a Starbucks spokesperson. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The theory that they are products of the radiation from the bomb is genius.\nQuestion: They are products of the radiation from the bomb. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Adenoiditis symptoms often persist for ten or more days, and often include pus-like discharge from nose.\nQuestion: Adenoiditis symptoms often pass within ten days or less, and often include pus-like discharge from nose. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "I wish I could give both of you an upvote to share.\nQuestion: I wish I could give an upvote to both of you to share. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Chicago City Hall is the official seat of government of Chicago.\nQuestion: Chicago City Hall is the official seat of government of the City of Chicago. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The leading car shifted to the left lane.\nQuestion: The leading car gradually shifted to the left lane. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "It's the perfect reverse psychology tactic.\nQuestion: If you think about it, it's the perfect reverse psychology tactic. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "I don't want to have to keep fighting pesky bedbugs.\nQuestion: I don't want to have to keep fighting bedbugs—they are so pesky. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "He abandoned the radical teachings of the Nation of Islam in favor of mainstream Islam after a pilgrimage to Mecca where he witnessed Muslims of all races coming together in solidarity.\nQuestion: He abandoned the radical teachings of the Nation of Islam in favor of mainstream Islam due in part to a pilgrimage to Mecca where he witnessed Muslims of all races coming together in solidarity. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Russia’s ruling projects an image of unity, but is divided along many lines — between security hawks and economic liberals, between people with personal vendettas, and between competing business interests.\nQuestion: Russia’s ruling system, while projecting an image of unity, is divided along many lines — between security hawks and economic liberals, between people with personal vendettas, and between competing business interests. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Notorious B.I.G. passed away.\nQuestion: During Notorious B.I.G.'s funeral procession through the streets of Brooklyn, someone interrupted the somber atmosphere by playing \"Hyponotize\" at full volume, which prompted the public to dance and sing along. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "We propose models from which the attested vowel inventories have been drawn.\nQuestion: We propose models of the probability distribution from which the attested vowel inventories have been drawn. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "An experienced sommelier knows the difference between the 2009 and 2013 vintage of a German Riesling.\nQuestion: A sommelier knows the difference between the 2009 and 2013 vintage of a German Riesling. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The book astounds with Grossman's rich, deep character development and portrayal of suffering, but his portrayal of women still suffers from a lot of the unfortunate stereotypes and moralizing that we would expect of a writer from his time.\nQuestion: The book astounds as Grossman richly, deeply develops characters and portrays suffering, but his portrayal of women still suffers from a lot of the unfortunate stereotypes and moralizing that we would expect of a writer from his time. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The battlecruiser Seydlitz struck a mine while en route to the target, and was destroyed.\nQuestion: The battlecruiser Seydlitz struck a mine while en route to the target, and had to withdraw. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Furthermore, the French dangerously underestimated Austrian tenacity and military skill.\nQuestion: Furthermore, the French dangerously underestimated Austrian military skill and tenacity. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Mueller received a mandate to investigate possible collusion with vast resources.\nQuestion: Mueller received a mandate to investigate possible collusion. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Albertosaurus and other tyrannosaurids were heterodont, with lots of teeth.\nQuestion: Albertosaurus and other tyrannosaurids were heterodont, with teeth of different forms depending on their position in the mouth. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Tex signed the contract.\nQuestion: Jacob did not see Tex sign the contract. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Relation extraction systems populate knowledge bases with facts from unstructured text corpora.\nQuestion: Knowledge bases are populated with facts from unstructured text corpora by relation extraction systems. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "We manually annotated over 690 templates mapping KB predicates to text for different compositionality types (with 462 unique KB predicates), and use those templates to modify the original WebQuestionsSP question according to the meaning of the generated SPARQL query.\nQuestion: We manually annotated 687 templates mapping KB predicates to text for different compositionality types (with 462 unique KB predicates), and use those templates to modify the original WebQuestionsSP question according to the meaning of the generated SPARQL query. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Just watched the first 15 minutes, got bored, skipped to the magic bit, it's funnier as a GIF.\nQuestion: Just watched the first 10 minutes, got bored, skipped to the magic bit, it's funnier as a GIF. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The Sydney area has been inhabited by Aboriginal people for at least 30,000 years.\nQuestion: The Sydney area has been inhabited by indigenous Australians for at least 30,000 years. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "After being denied, he grew angry and ignored the police officer's warnings to relax, so he was handcuffed and taken to the station.\nQuestion: After being denied, he grew angry and ignored the police officer's warnings to relax, so he was arrested. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "We publicly share our dataset and code for future research.\nQuestion: We publicly share our dataset for future research. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Tom and Adam were whispering in the theater.\nQuestion: Tom and Adam were whispering quietly in the theater. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Considering this definition, it is not surprising to find frequent use of sarcastic language in opinionated user generated content.\nQuestion: Considering this definition, it is surprising to find frequent use of sarcastic language in opinionated user generated content. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The first experience I had interacting with another human being was at the age of seventeen.\nQuestion: The first pleasurable experience I had interacting with another human being was at the age of seventeen. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "I wish I could give both of you an upvote to share.\nQuestion: I wish both of you could get an upvote from me to share. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "He abandoned the radical teachings of the Nation of Islam in favor of mainstream Islam after a pilgrimage to Mecca where he witnessed Muslims of all races coming together in solidarity.\nQuestion: He abandoned the radical teachings of the Nation of Islam in favor of mainstream Islam until a pilgrimage to Mecca where he witnessed Muslims of all races coming together in solidarity. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Semantic parsing typically requires using a set of operations to query the knowledge base and process the results.\nQuestion: Semantic parsing typically needs a set of operations to query the knowledge base and process the results. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Tom and Adam were whispering quietly in the theater.\nQuestion: Tom and Adam were whispering in the theater. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Microsoft has said that corrective action might be taken even if no policy violation was found, and that the person who filed the complaint might not be informed.\nQuestion: Microsoft has said that corrective action might not be taken even if a policy violation was found, and that the person who filed the complaint might not be informed. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "If Charles' left wing, commanded by Nauendorf, united with Hotze's force, approaching from the east, Masséna knew Charles would attack and very likely push him out of Zürich.\nQuestion: If Charles' left wing, commanded by Nauendorf, united with Hotze's force, approaching from the east, Masséna doubted Charles would attack and push him out of Zürich. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "No bathroom bill made it to Abbott’s desk by the end of the legislative session in May.\nQuestion: A bill made it to Abbott’s desk by the end of the legislative session in May. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "A calm wind rolled across the glade.\nQuestion: A serene wind rolled across the glade. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "We publicly share our dataset for future research.\nQuestion: We publicly share our dataset and code for future research. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The doctor does not bear responsibility for successful care.\nQuestion: Both doctor and patient bear some responsibility for successful care. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Ferrero SpA, the maker of Nutella and Ferrero Rocher, uses almost 25% of the global supply of hazelnuts.\nQuestion: Ferrero SpA, the maker of Nutella and Ferrero Rocher, uses 25% of the global supply of hazelnuts. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "They should be attached to the lifting mechanism in the faucet.\nQuestion: They should be attached in the faucet. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Everyone has a set of principles to live by.\nQuestion: Susan doesn't have a set of principles to live by. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Lexical features can hardly generalize to unseen domains.\nQuestion: We show that if coreference resolvers mainly rely on lexical features, they can hardly generalize to unseen domains. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "It's not the case that there is no rabbi at this wedding; he is right there standing behind that tree.\nQuestion: There is a rabbi at this wedding; he is right there standing behind that tree. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "We manually annotated 687 templates mapping KB predicates to text for different compositionality types (with 462 unique KB predicates), and use those templates to modify the original WebQuestionsSP question according to the meaning of the generated SPARQL query.\nQuestion: We manually annotated over 650 templates mapping KB predicates to text for different compositionality types (with 462 unique KB predicates), and use those templates to modify the original WebQuestionsSP question according to the meaning of the generated SPARQL query. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The longer he stays in power, the harder it will be to exit.\nQuestion: The shorter he stays in power, the easier it will be to exit. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The Sydney area has been inhabited by Europeans for at least 30,000 years.\nQuestion: The Sydney area has been inhabited by indigenous Australians for at least 30,000 years. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "You know that some life changing actions must be taken when grandma reacts with the sad emoji.\nQuestion: You know that some life-changing actions must be taken when grandma reacts with emoji. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "In grounded communication tasks, speakers face pressures in choosing referential expressions that distinguish their targets from others in the context, leading to many kinds of meaning enrichment.\nQuestion: In grounded communication tasks, speakers face pressures in choosing referential expressions that distinguish their targets from others in the context, leading to many kinds of pragmatic meaning enrichment. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Temple said that the business was facing difficulties, but didn't have a chance of going into the red.\nQuestion: Temple said the business didn't have a chance of going into the red. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Considering this definition, it is surprising to find frequent use of sarcastic language in opinionated user generated content.\nQuestion: Considering this definition, it is not surprising to find frequent use of sarcastic language in opinionated user generated content. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Working hours go up as you look further back in time from 1940.\nQuestion: In the 1890's a typical worker worked 60 hours per week; down to 48 by 1920 and 40 by 1940. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "To compute the perplexity numbers on the test data, our model only takes account of log probabilities on word prediction.\nQuestion: To compute the perplexity numbers on the test data, our model doesn't take account of anything other than the log probabilities on word prediction. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The Sydney area has been inhabited by indigenous Australians for at least 30,000 years.\nQuestion: The Sydney area has been inhabited by Aboriginal people for at least 30,000 years. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "My jokes reflect exactly zero of my character.\nQuestion: If everyone believed my jokes, they'd know exactly who I was. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Semantic parsing typically requires using a set of operations to query the knowledge base and process the results.\nQuestion: Semantic parsing infrequently creates a set of operations to query the knowledge base and process the results. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Knowledge bases are populated by relation extraction systems with facts from unstructured text corpora.\nQuestion: Relation extraction systems populate knowledge bases with facts from unstructured text corpora. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "We propose models of the probability distribution from a restricted space of linear functions.\nQuestion: We propose models from a restricted space of linear functions. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Mueller’s team asked former senior Justice Department officials for information.\nQuestion: Former senior Justice Department officials weren't asked for information. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The window was broken by John.\nQuestion: John broke the window. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Temple said that the business was facing difficulties, but didn't have a chance of going into the red.\nQuestion: Temple didn't have a chance of going into the red. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "She is a skilled violinist.\nQuestion: She is skilled at violin. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The Republican party almost universally opposed that bill in 2009, which cost $787 billion over 10 years, on the grounds that it would increase the debt too much.\nQuestion: The Republican party would increase the debt too much. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "We show that if coreference resolvers mainly rely on lexical features, they can hardly generalize to unseen domains.\nQuestion: Coreference resolvers can hardly generalize to unseen domains. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "I couldn’t bring myself to throw it away, not out of the fondness of all the memories surrounding that time period.\nQuestion: I couldn’t bring myself to throw it away, not out of affection to her, but rather the fondness of all the memories surrounding that time period. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "It reminds me of the times my little brother and I played Super Mario.\nQuestion: It reminds me of the times I played Super Mario with my little brother. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "I did not fail my resolutions in 2004.\nQuestion: I have failed my resolutions every year since 1997, and it's now 2008. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "This means that solving analogy questions with vector arithmetic is mathematically equivalent to seeking a word that is similar to x and y but is different from z.\nQuestion: This means that seeking a word that is similar to x and y but is different from z is mathematically equivalent to solving analogy questions with vector arithmetic. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Temperature must be just right.\nQuestion: Temperature and snow consistency must be just right. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Supply and demand... scarcity... all these economic principles that determine the cost of things really boil down to the value of human labor.\nQuestion: Supply and demand... scarcity... all these economic principles that determine the cost of things are related to the value of human labor. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "No bills made it to Abbott’s desk by the end of the legislative session in May.\nQuestion: No bathroom bill made it to Abbott’s desk by the end of the legislative session in May. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Our experiments indicate that neural systems are quite good at capturing higher level semantics and structure but perform quite poorly at surface-level language modeling.\nQuestion: Our experiments indicate that neural systems are quite good at producing fluent outputs and generally score well on standard word-match metrics, but perform quite poorly at content selection and at capturing long-term structure. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Temple didn't have a chance of going into the red.\nQuestion: Temple said that the business was facing difficulties, but didn't have a chance of going into the red. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Most of the graduates of my program have moved on to other things because the jobs suck.\nQuestion: Some of the graduates of my program have moved on to other things because the jobs suck. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "I can actually see him climbing into a Lincoln saying this.\nQuestion: I can actually see him getting into a Lincoln saying this. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Due to inadequate funding, 76 T and the rest of the 250t class were essentially coastal vessels, despite the original intention that they would be used for \"high seas\" operations.\nQuestion: Due to inadequate funding, 76 T and the rest of the 250t class were essentially high seas vessels, despite the original intention that they would be used for coastal operations. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Albertosaurus and other tyrannosaurids were heterodont, with teeth of different forms depending on their position in the mouth.\nQuestion: Albertosaurus and other tyrannosaurids were heterodont. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The corn overshadowed several adjacent rows of beans.\nQuestion: The climbing beans choked the corn, and the squash grew so big that it overshadowed several adjacent rows of beans. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "In example (1) it is quite easy to see the exaggerated positive sentiment used in order to convey strong negative feelings.\nQuestion: In example (1) it is quite straightforward to see the exaggerated positive sentiment used in order to convey strong negative feelings. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The reaction was strongly exothermic.\nQuestion: The reaction media got very hot. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The problem in Ireland was lack of food.\nQuestion: The problem in Ireland was not lack of food, which was plentiful, but the price of it, which was beyond the reach of the poor. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Soft plant parts and insects are eaten.\nQuestion: Cape sparrows eat seeds, along with soft plant parts and insects. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Life is either a daring adventure or nothing at all.\nQuestion: Life is nothing at all. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "We propose models of the probability distribution from a restricted space of linear functions.\nQuestion: We propose models of the probability distribution. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "In practice, our proposed extractive evaluation will pick up on many errors in this passage.\nQuestion: In practice, our proposed extractive evaluation will pick up on few errors in this passage. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The announcement represents a significant hardening of Britain's posture toward Russia, with which it has had a valuable intelligence-sharing relationship.\nQuestion: The announcement represents a significant change in Britain's posture toward Russia, with which it has had a valuable intelligence-sharing relationship. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The Saudi Embassy in Washington denied to NBC the claims that the princess is separated from her husband or under house arrest.\nQuestion: Representatives of the Saudi government denied to NBC the claims that the princess is separated from her husband or under house arrest. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Though the power grab has earned Xi comparisons to leaders such as Turkey’s Recep Tayyip Erdogan, his vision for China is singular — and will have an impact well beyond China’s borders.\nQuestion: Though the power grab has earned Xi comparisons to leaders such as Turkey’s Recep Tayyip Erdogan and Russia’s Vladimir Putin, his vision for China is singular — and will have an impact well beyond China’s borders. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "There is no rabbi at this wedding, let alone behind that tree.\nQuestion: It's not the case that there is no rabbi at this wedding; he is right there standing behind that tree. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Understanding a long document requires tracking how entities are introduced and evolve over time.\nQuestion: Understanding a long document requires tracking how entities evolve over time. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Our experiments indicate that neural systems are quite good at surface-level language modeling, but perform quite poorly at capturing higher level semantics and structure.\nQuestion: Our experiments indicate that neural systems are quite good at producing fluent outputs and generally score well on standard word-match metrics, but perform quite poorly at content selection and at capturing long-term structure. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Spee went down with the ship.\nQuestion: All 860 officers and men on board, including Spee, went down with the ship. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The Cape sparrow's population has not decreased significantly, and is not seriously threatened by human activities.\nQuestion: The population of the Cape sparrow has decreased significantly, and is seriously threatened by human activities. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Our deepest sympathies are with all those affected by this accident.\nQuestion: Our deepest sympathies are with a victim who was affected by this accident. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The water is too hot.\nQuestion: The water is too cold. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Kappa Pyxidis was catalogued but not given a Bayer designation by Lacaille, but Gould felt the star was bright enough to warrant a letter.\nQuestion: Lacaille and Gould agreed about the designation of Kappa Pyxidis. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Last time I visited was nearly 6 months ago and I am still finding husky fur on my socks.\nQuestion: Last time I visited was more than 6 months ago and I am still finding husky fur on my socks. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Representatives of the Saudi government denied to NBC the claims that the princess is separated from her husband or under house arrest.\nQuestion: The Saudi Embassy in Washington denied to NBC the claims that the princess is separated from her husband or under house arrest. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The population of the Cape sparrow has not decreased significantly, and is not seriously threatened by human activities.\nQuestion: The Cape sparrow's population has not decreased significantly, and is not seriously threatened by human activities. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "An experienced sommelier knows the difference between the 2009 and 2013 vintage of a German Riesling.\nQuestion: An Italian sommelier knows the difference between the 2009 and 2013 vintage of a German Riesling. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Cape sparrows eat seeds, along with soft plant parts and insects.\nQuestion: Soft plant parts and insects eat seeds. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "In example (1) it is quite straightforward to see the exaggerated positive sentiment used in order to convey strong negative feelings.\nQuestion: In example (1) it is quite difficult to see the exaggerated positive sentiment used in order to convey strong negative feelings. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Dave was wet.\nQuestion: Dave jumped into the lake. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "He does not have a blind trust.\nQuestion: Either he has a blind trust or he has a conflict of interest. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "She was the eldest of four children, the only girl, and \"learned to exercise her native discretion, firmness, and tact\" by resolving her three younger brothers' petty boyhood squabbles.\nQuestion: She was the eldest of four children, the only girl, and \"learned to exercise her native discretion, firmness, and tact\" by resolving her three brothers' petty boyhood squabbles. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Either he has a blind trust or he has a conflict of interest.\nQuestion: He has a conflict of interest. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "There was a book I was trying to import and I saw that it was finally available with Amazon Prime shipping and I ended up paying like double the other prices to have it in 2 days vs. 2 weeks.\nQuestion: I waited until Prime availability and paid a higher sticker price for a book so I could get free 2-day shipping. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Regional governors could not rely on the king for help in times of crisis, and the ensuing food shortages and political disputes escalated into famines and small-scale civil wars.\nQuestion: Regional governors could not rely on anyone for help in times of crisis, and the ensuing food shortages and political disputes escalated into famines and small-scale civil wars. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Semantic parsing typically creates a set of operations to query the knowledge base and process the results.\nQuestion: Semantic parsing typically requires using a set of operations to query the knowledge base and process the results. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Due to the structure and short length of most Wikipedia documents (median number of sentences: 9), the answer can usually be inferred from the first few sentences.\nQuestion: Due to the structure and short length of most Wikipedia documents (median number of sentences: 9), the answer can always be inferred from the first few sentences. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "From a quick Google search, Bitcoin Cash was created as a hard fork of Bitcoin and Bitcoin's supposed to be faster and more sustainable.\nQuestion: From a quick Google search, Bitcoin Cash was created as a hard fork of Bitcoin and it's supposed to be faster and more sustainable. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "If Charles' left wing, commanded by Nauendorf, united with Hotze's force, approaching from the east, Masséna would prepare for Charles to attack and very likely push him out of Zürich.\nQuestion: If Charles' left wing, commanded by Nauendorf, united with Hotze's force, approaching from the east, Masséna knew Charles would attack and very likely push him out of Zürich. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "I wish I could give an upvote to both of you to share.\nQuestion: I wish I could give both of you an upvote to share. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The track was originally titled \"Seibu\" and was left off the album before it was rediscovered later during the recording sessions.\nQuestion: The track was originally titled \"Seibu\" and was almost left off the album before it was rediscovered later during the recording sessions. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Eliminating the influence of the language model yields the following coherence score.\nQuestion: We thus propose eliminating the influence of the language model, which yields the following coherence score. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "In an Oval Office meeting after Mueller's appointment, Trump told Sessions he should resign, prompting the attorney general to submit a letter of resignation, according to The New York Times.\nQuestion: In an Oval Office meeting after Mueller's appointment, Trump told Sessions he should resign, prompting the attorney general's submission of a letter of resignation, according to The New York Times. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "During World War II, the five remaining Greek boats were sunk by Axis aircraft during the Greek invasion of Germany in April 1941.\nQuestion: During World War II, the five remaining Greek boats were sunk by Axis aircraft during the German invasion of Greece in April 1941. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Mary left before John entered.\nQuestion: John entered before Mary left. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The market is about to get harder, but possible to navigate.\nQuestion: The market is about to get harder, but not impossible to navigate. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Often, the first step in building statistical NLP models involves extracting features.\nQuestion: Often, the first step in building statistical NLP models involves feature extraction. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The problem in Ireland was not lack of food, which was plentiful, but the price of it, which was beyond the reach of the poor.\nQuestion: The problem in Ireland was lack of food. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "John entered after Mary left.\nQuestion: Mary left before John entered. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "I can't believe it's not butter.\nQuestion: It's not butter. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "I had already finished it.\nQuestion: She didn't think I had already finished it, but I had. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "I baked him a cake.\nQuestion: I baked him. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "John broke the window.\nQuestion: The window broke John. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "All speech is political speech.\nQuestion: Joan believes that all speech is political speech. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Falcon Heavy is the smallest rocket since NASA's Saturn V booster, which was used for the Moon missions in the 1970s.\nQuestion: Falcon Heavy is the largest rocket since NASA's Saturn V booster, which was used for the Moon missions in the 1970s. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Russians have identified a nerve agent used in a suspected chemical attack on British soil.\nQuestion: Russia vowed Tuesday to retaliate if Britain imposes sanctions in response to a suspected chemical attack on British soil and demanded access to samples of a nerve agent that British investigators say they have identified as Russian. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "In construction of the Empire State Building, Bass River timber was used.\nQuestion: Bass River timber was used in construction of the Empire State Building. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Bees do not follow the same rules as airplanes.\nQuestion: Bees are more energy-efficient flyers than airplanes. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "After being denied, he grew angry and ignored the police officer's warnings to relax, so he was escorted home.\nQuestion: After being denied, he grew angry and ignored the police officer's warnings to relax, so he was handcuffed and taken to the station. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Both doctor and patient bear some responsibility for successful care.\nQuestion: The patient bears some responsibility for successful care. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Deep neural networks have achieved impressive performance in supervised classification and structured prediction tasks.\nQuestion: Decision trees have achieved impressive performance in supervised classification and structured prediction tasks. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "I ate pizza.\nQuestion: I ate pizza with friends. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The new general artificial intelligence I'm developing should come with an off switch.\nQuestion: A general artificial intelligence should always come with an off switch. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The market is about to get harder, but not impossible to navigate.\nQuestion: The market is about to get harder, but possible to navigate. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "Top U.S. intelligence officials met with the head of Russia's foreign spy service, despite existing sanctions.\nQuestion: The head of Russia's foreign spy service met with top U.S. intelligence officials, despite existing sanctions. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "To generate diversity, workers got a bonus if the edit distance of a paraphrase was high compared to the MG question.\nQuestion: To generate diversity, workers whose paraphrases had high edit distance compared to the MG question got a bonus. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The problem in Ireland was not lack of food, which was plentiful, but the price of it, which was beyond the reach of the poor.\nQuestion: The poor in Ireland had plentiful food. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The pharaohs of the Middle Kingdom restored the country's stability and prosperity, thereby stimulating a resurgence of art, literature, and monumental building projects.\nQuestion: The pharaohs of the Middle Kingdom of Egypt restored the country's stability and prosperity, thereby stimulating a resurgence of art, literature, and monumental building projects. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "All of the graduates of my program have moved on to other things because the jobs suck.\nQuestion: Most of the graduates of my program have moved on to other things because the jobs suck. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "They are products of the radiation from the bomb.\nQuestion: The theory that they are products of the radiation from the bomb is correct. True or False?", "choices": ["True", "False", "Neither"], "answer": "True", "label": "MUL"}
{"question": "The patient bears some responsibility for successful care.\nQuestion: Both doctor and patient bear some responsibility for successful care. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Jake broke.\nQuestion: Jake broke the vase. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "Grisham did not win the popular vote.\nQuestion: Grisham tried to win the popular vote. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "I can make scrambled eggs, but not complex dishes like consommé.\nQuestion: Consommé is not more complex to make than scrambled eggs. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
{"question": "The problem in Ireland was the price of food.\nQuestion: The problem in Ireland was not lack of food, which was plentiful, but the price of it, which was beyond the reach of the poor. True or False?", "choices": ["True", "False", "Neither"], "answer": "False", "label": "MUL"}
